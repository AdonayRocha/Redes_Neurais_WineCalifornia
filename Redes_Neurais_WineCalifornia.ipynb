{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6b/HnRvZ2c+iu6jiXXKND",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdonayRocha/Redes_Neurais_WineCalifornia/blob/main/Redes_Neurais_WineCalifornia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Checkpoint 2 - Redes Neurais com Keras**\n",
        "Adonay Rodrigues da Rocha - RM558782 <br>\n",
        "Pedro Henrique Martins Dos Reis - RM555306 <br>\n",
        "Thamires Ribeiro Cruz - RM558128 <br>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YX3gYEgfYtcn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introdução** <br>\n",
        "O dataset escolhido foi o Wine, um conjunto de dados clássico disponível diretamente na biblioteca scikit-learn (https://scikit-learn.org/1.1/modules/generated/sklearn.datasets.load_wine.html). <br>\n",
        "A escolha pelo Wine se justifica por ele ser amplamente utilizado em tarefas de classificação multiclasse, sendo composto por **178 amostras de vinhos**, cada uma descrita por **13 atributos**. <br>\n",
        "Além disso, o Wine dataset é frequentemente utilizado como benchmark em estudos de machine learning, facilitando a comparação e interpretação dos resultados obtidos com diferentes modelos. <br>\n",
        "A facilidade de acesso (Disponível via função load_wine), a boa documentação e o formato já pronto para uso em experimentos tornam este dataset ideal para o objetivo da atividade, que é testar e comparar modelos de classificação com redes neurais e algoritmos clássicos."
      ],
      "metadata": {
        "id": "a6oyFRtWaM7o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTo8RmvfQmIT"
      },
      "outputs": [],
      "source": [
        "# Import das bibliotecas\n",
        "from IPython.display import Markdown as md\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercicío 1: WineDataset Classificação Multiclasse\n",
        "Carregamos o Wine Dataset, disponível na biblioteca scikit-learn, para realizar uma classificação em três classes utilizando uma rede neural construída com Keras. O conjunto de dados foi dividido em treino e teste para garantir uma avaliação justa, e os rótulos foram transformados em formato one-hot, conforme exigido pelo modelo. A arquitetura utilizada seguiu as recomendações do exercício, com duas camadas ocultas de 32 neurônios e ativação ReLU, e uma camada de saída com três neurônios e ativação Softmax, sendo avaliada pela métrica de acurácia."
      ],
      "metadata": {
        "id": "05CdkbdmZbBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando os dados\n",
        "wine = load_wine()\n",
        "X_wine = wine.data\n",
        "y_wine = wine.target"
      ],
      "metadata": {
        "id": "ZlqQCeZxc3tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separando treino e teste\n",
        "Xw_train, Xw_test, yw_train, yw_test = train_test_split(X_wine, y_wine, test_size=0.2, random_state=42)\n",
        "\n",
        "# Transformando alvo para one-hot para Keras\n",
        "yw_train_categorical = to_categorical(yw_train, num_classes=3)\n",
        "yw_test_categorical = to_categorical(yw_test, num_classes=3)\n",
        "\n",
        "# Rede Neural com Keras\n",
        "model_wine = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(X_wine.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "model_wine.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_wine = model_wine.fit(Xw_train, yw_train_categorical, epochs=50, batch_size=16, verbose=0, validation_split=0.1)\n",
        "\n",
        "wine_loss, wine_acc = model_wine.evaluate(Xw_test, yw_test_categorical, verbose=0)\n",
        "print(f'Acurácia (Keras NN): {wine_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1poX1h6RAy5",
        "outputId": "d9656f69-bdaa-4d2e-9a76-7a6670e8cce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia (Keras NN): 0.8333\n",
            "Acurácia (RandomForest): 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para fins de comparação e atividade, também treinamos um modelo clássico de machine learning utilizando o RandomForestClassifier da biblioteca scikit-learn."
      ],
      "metadata": {
        "id": "R7M2V6ggch2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo scikit-learn\n",
        "rf_wine = RandomForestClassifier(n_estimators=100)\n",
        "rf_wine.fit(Xw_train, yw_train)\n",
        "yw_pred_rf = rf_wine.predict(Xw_test)\n",
        "rf_acc = accuracy_score(yw_test, yw_pred_rf)\n",
        "print(f'Acurácia (RandomForest): {rf_acc:.4f}')"
      ],
      "metadata": {
        "id": "AK4fMxb_Zhuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os resultados mostram que, no Wine Dataset, o RandomForestClassifier apresentou acurácia superior à rede neural construída com Keras. Isso ocorre porque algoritmos de árvores, como o Random Forest, costumam ser mais eficazes em conjuntos de dados tabulares com variáveis bem definidas e relações não-lineares, aproveitando o ensemble de múltiplas árvores para capturar padrões complexos sem exigir ajuste fino de hiperparâmetros ou grande quantidade de dados. Já as redes neurais podem demandar mais dados e ajustes para superar modelos clássicos em problemas desse tipo. Portanto, neste cenário, o RandomForestClassifier foi a melhor escolha para maximizar a acurácia."
      ],
      "metadata": {
        "id": "uj7MN49PZkF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "md(f\"\"\"\n",
        "**Resultados Wine Dataset:**\n",
        "- Acurácia Keras NN: `{wine_acc:.4f}`\n",
        "- Acurácia RandomForest: `{rf_acc:.4f}`\n",
        "\n",
        "O modelo que apresentou maior acurácia foi: `{\"Rede Neural Keras\" if wine_acc > rf_acc else \"RandomForestClassifier\"}`.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "Ki6XswjdRKNK",
        "outputId": "44f04be8-67b4-4c71-9b49-3d1aaab37423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n**Resultados Wine Dataset:**\n- Acurácia Keras NN: `0.8333`\n- Acurácia RandomForest: `1.0000`\n\nO modelo que apresentou maior acurácia foi: `RandomForestClassifier`.\n"
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercício 2: Regressão (California Housing)\n",
        "Neste exercício, utilizamos o California Housing Dataset, disponível na biblioteca scikit-learn, para realizar uma tarefa de regressão, prevendo o valor médio das casas. O conjunto de dados foi dividido em treino e teste, garantindo avaliação adequada dos modelos. Construímos uma rede neural com Keras composta por três camadas ocultas de 64, 32 e 16 neurônios com ativação ReLU, e uma camada de saída linear, utilizando a métrica MAE para avaliação. Em paralelo, treinamos um modelo RandomForestRegressor, calculando RMSE e MAE para comparar o desempenho. Essa abordagem permite analisar qual modelo é mais eficiente para prever valores contínuos em dados tabulares."
      ],
      "metadata": {
        "id": "cNRiX2GwdHC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O **California Housing Dataset** foi escolhido por ser um dos conjuntos de dados mais conhecidos e utilizados para tarefas de regressão em aprendizado de máquina. Disponível diretamente na **biblioteca scikit-learn**, ele contém informações detalhadas sobre diferentes regiões da Califórnia, como renda média, idade média das casas, número de quartos e população, com o objetivo de prever o valor médio das casas em cada área. Sua estrutura tabular, com variáveis numéricas e contínuas, torna o dataset ideal para testar e comparar modelos de regressão supervisionada, como redes neurais e algoritmos clássicos, além de facilitar a replicação de experimentos e a interpretação dos resultados."
      ],
      "metadata": {
        "id": "8AyITQz2d_nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando os dados\n",
        "housing = fetch_california_housing()\n",
        "X_house = housing.data\n",
        "y_house = housing.target\n",
        "\n",
        "# Separando treino e teste\n",
        "Xh_train, Xh_test, yh_train, yh_test = train_test_split(X_house, y_house, test_size=0.2, random_state=42)\n",
        "\n",
        "# Rede Neural com Keras\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "model_house = Sequential([\n",
        "    Input(shape=(X_house.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "model_house.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "history_house = model_house.fit(Xh_train, yh_train, epochs=50, batch_size=32, verbose=0, validation_split=0.1)\n",
        "\n",
        "house_loss, house_mae = model_house.evaluate(Xh_test, yh_test, verbose=0)\n",
        "print(f'MAE (Keras NN): {house_mae:.4f}')\n",
        "\n",
        "# Modelo scikit-learn\n",
        "rf_house = RandomForestRegressor(n_estimators=100)\n",
        "rf_house.fit(Xh_train, yh_train)\n",
        "yh_pred_rf = rf_house.predict(Xh_test)\n",
        "rf_mse = mean_squared_error(yh_test, yh_pred_rf)\n",
        "rf_rmse = rf_mse ** 0.5\n",
        "rf_mae = mean_absolute_error(yh_test, yh_pred_rf)\n",
        "print(f'RMSE (RandomForest): {rf_rmse:.4f}')\n",
        "print(f'MAE (RandomForest): {rf_mae:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpOMVTkLRQlJ",
        "outputId": "ee986c32-5938-4ec8-eb73-4edcf93df242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE (Keras NN): 0.6020\n",
            "RMSE (RandomForest): 0.5025\n",
            "MAE (RandomForest): 0.3249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No teste de regressão com o California Housing Dataset, o modelo RandomForest teve desempenho melhor do que a rede neural, apresentando um erro menor. Isso acontece porque o RandomForest consegue lidar muito bem com dados tabulares, encontrando padrões entre as variáveis sem precisar de muitos ajustes. Já as redes neurais geralmente precisam de mais dados e de uma configuração mais específica para superar modelos como o RandomForest nesse tipo de tarefa. Por isso, neste caso, o RandomForest foi mais eficiente para prever os valores das casas."
      ],
      "metadata": {
        "id": "w9u0cBPDefXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "md(f\"\"\"\n",
        "**Resultados California Housing:**\n",
        "- Mean Absolute Error Keras: `{house_mae:.4f}`\n",
        "- Root Mean Squared Error RandomForest: `{rf_rmse:.4f}`\n",
        "- Mean Squared Error RandomForest: `{rf_mae:.4f}`\n",
        "\n",
        "O modelo com menor erro foi: `{\"Rede Neural Keras\" if house_mae < rf_mae else \"RandomForestRegressor\"}`.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "Fojykx6jRabh",
        "outputId": "659eb021-d595-4256-ccde-23dcde16ddcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n**Resultados California Housing:**\n- MAE Keras NN: `0.6954`\n- RMSE RandomForest: `0.5056`\n- MAE RandomForest: `0.3272`\n\nO modelo com menor erro foi: `RandomForestRegressor`.\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}